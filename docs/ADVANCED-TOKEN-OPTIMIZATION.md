# Advanced Token Optimization Strategies

**Version:** 1.0.0
**Created:** 2026-02-10
**Purpose:** Reduce token consumption beyond basic optimizations

---

## üìä Current Token Usage Analysis

**Current Optimizations (Already Active):**
1. ‚úÖ Read tool: offset/limit for files >500 lines
2. ‚úÖ Grep tool: head_limit (default 100)
3. ‚úÖ Cache: Files accessed 3+ times
4. ‚úÖ Batch ops: Combine commands
5. ‚úÖ Brief responses: Action first

**Token Budget Breakdown:**
- Context window: ~200K tokens
- Conversation history: ~40-60%
- File reads: ~20-30%
- Tool outputs: ~10-20%
- MCP responses: ~5-10%

---

## üöÄ ADVANCED OPTIMIZATIONS (New)

### 1. **Smart File Summarization** (HIGH IMPACT)

**Problem:** Even with offset/limit, large files consume tokens

**Solution:** Auto-summarize instead of full read

**Implementation:**
```python
# Before reading large file:
if file_size > 1000 lines:
    # Option 1: Read strategic sections
    - Read first 50 lines (imports, structure)
    - Read last 50 lines (recent changes)
    - Skip middle (less relevant)

    # Option 2: AST-based summary (for code)
    - Extract: classes, functions, signatures
    - Skip: function bodies (read only when needed)

    # Option 3: Cached summary
    - Check if summary exists in cache
    - Use summary instead of full read
```

**Token Savings:** 70-80% on large files

---

### 2. **Tiered Caching Strategy** (MEDIUM IMPACT)

**Current:** Cache files accessed 3+ times

**Enhanced:** Hot/Warm/Cold tiers

**Implementation:**
```python
# Tier 1: HOT (accessed 5+ times in last hour)
- Keep full content in memory
- No re-reads needed
- Examples: Main config files, constants

# Tier 2: WARM (accessed 3-4 times)
- Keep summary in cache
- Re-read only on explicit request
- Examples: Service implementations

# Tier 3: COLD (accessed 1-2 times)
- No caching
- Read fresh each time
- Examples: One-time reads
```

**Token Savings:** 30-40% on repeated operations

---

### 3. **Diff-Based Editing** (HIGH IMPACT)

**Problem:** After editing, showing full file again

**Solution:** Show only changed sections

**Implementation:**
```python
# After Edit tool:
Instead of showing full file (all 500 lines)
Show only:
- Lines changed (5-10 lines)
- 3 lines context before/after
- Total: ~20 lines instead of 500

Example:
  ... (lines 1-42 unchanged)
  43: OLD CODE
  44: NEW CODE ‚Üê Changed
  45: OLD CODE
  ... (lines 46-500 unchanged)
```

**Token Savings:** 90% on edit confirmations

---

### 4. **Intelligent Grep Filtering** (MEDIUM IMPACT)

**Current:** head_limit=100

**Enhanced:** Smart pattern refinement

**Implementation:**
```python
# Step 1: Run broad search
grep "function" --head_limit=10  # Just 10 to estimate

# Step 2: If too many results, refine
if results > 50:
    # Add context to narrow down
    grep "function.*User" --head_limit=20

# Step 3: Use file type filters
grep "function" --type=ts --glob="*service*"
```

**Token Savings:** 50-60% on searches

---

### 5. **Response Compression** (LOW IMPACT, EASY)

**Problem:** My responses are verbose

**Solution:** Ultra-brief mode for routine tasks

**Implementation:**
```markdown
# BEFORE (Verbose):
"I'll now read the configuration file to check the database settings.
Let me use the Read tool to examine the contents..."

# AFTER (Compressed):
"Reading config..."

# BEFORE (Verbose):
"The file has been successfully updated. I've changed the port from
8080 to 3000 as requested. Here's what I modified..."

# AFTER (Compressed):
"‚úÖ Port: 8080 ‚Üí 3000"
```

**Token Savings:** 20-30% on my responses

---

### 6. **AST-Based Code Navigation** (HIGH IMPACT)

**Problem:** Reading full Java/TypeScript files to find one class

**Solution:** Parse AST, show only structure

**Implementation:**
```python
# Instead of reading 500-line Java file:
Read full file (500 lines √ó ~4 tokens = 2000 tokens)

# Use AST parser:
Parse structure only:
- Package: com.techdeveloper.auth
- Classes: [AuthController, AuthService, AuthHelper]
- Methods: [login(), register(), validateToken()]
Total: ~100 tokens (95% savings!)

# Read full method only when needed:
"Show me the login() method"
‚Üí Read lines 45-67 only
```

**Token Savings:** 80-95% on code exploration

**Tools Needed:**
- Java: `jdtls` or `tree-sitter`
- TypeScript: `typescript` AST parser
- Python: `ast` module

---

### 7. **Session State Aggressive Mode** (HIGH IMPACT)

**Current:** Use session state when context >85%

**Enhanced:** Use session state ALWAYS for historical data

**Implementation:**
```python
# Store in session state, reference in conversation:

# BAD (Repeating context every time):
You: "What did we do in the last session?"
Me: "In the last session, we implemented authentication with JWT,
     created UserService, added login endpoint, configured Redis..."
     (200 tokens repeated every time)

# GOOD (Reference session state):
You: "What did we do in the last session?"
Me: "See session state: session-2026-02-10.md, tasks 1-5"
     (20 tokens, user can read file if needed)
```

**Token Savings:** 60-80% on historical references

---

### 8. **Batch File Operations** (MEDIUM IMPACT)

**Problem:** Multiple small file reads

**Solution:** Combine into single operation

**Implementation:**
```python
# BAD (3 separate tool calls):
Read: src/auth/controller.ts
Read: src/auth/service.ts
Read: src/auth/dto.ts

# GOOD (1 tool call with Glob + batch read):
Glob: src/auth/*.ts ‚Üí Get list
Then strategic reads based on task

# OR use tree + strategic reads:
tree src/auth --level 2 (structure only)
Then read only needed files
```

**Token Savings:** 40-50% on exploration tasks

---

### 9. **MCP Response Filtering** (MEDIUM IMPACT)

**Problem:** MCP servers return too much data

**Solution:** Extract only needed fields

**Implementation:**
```python
# MCP returns 500-line JSON response

# BAD: Process all 500 lines

# GOOD: Extract essentials immediately
result = mcp.call()
essential = {
    'status': result.status,
    'data': result.data[0:5],  # First 5 items only
    'error': result.error
}
# Discard rest (400 lines saved)
```

**Token Savings:** 70-80% on MCP operations

---

### 10. **Conversation Pruning** (LOW IMPACT)

**Problem:** Old irrelevant turns stay in context

**Solution:** Auto-prune completed tasks

**Implementation:**
```python
# After task completion:
Mark conversation turns as "completed"

# When context >70%:
Prune completed tasks:
- Save summary to session state
- Remove detailed conversation
- Keep only current task context
```

**Token Savings:** 30-40% on long sessions

---

### 11. **Smart Tool Selection** (MEDIUM IMPACT)

**Problem:** Using heavy tools for simple tasks

**Solution:** Choose lightest tool that works

**Decision Matrix:**
```
Need file list?
  ‚Üí tree (50 tokens) NOT ls -R (500 tokens)

Need to find class?
  ‚Üí Glob "**/*ClassName*.java" (20 tokens)
  NOT Grep "class ClassName" (200 tokens)

Need imports?
  ‚Üí Read file offset=0 limit=20 (100 tokens)
  NOT Read full file (2000 tokens)

Need function signature?
  ‚Üí Grep "def functionName" -A 2 (50 tokens)
  NOT Read full file (2000 tokens)
```

**Token Savings:** 50-70% on exploration

---

### 12. **Incremental Updates** (MEDIUM IMPACT)

**Problem:** Showing full state after every change

**Solution:** Show only deltas

**Implementation:**
```python
# Iterative development:

# Round 1: Show full implementation
# Round 2: "Added error handling" ‚Üí Show only new code
# Round 3: "Fixed typo" ‚Üí Show only fixed line

# BEFORE:
After each change, show full file (500 lines)
3 changes = 1500 lines total

# AFTER:
Round 1: 500 lines
Round 2: +10 lines (just error handling)
Round 3: 1 line (typo fix)
Total: 511 lines (70% savings!)
```

**Token Savings:** 60-70% on iterative work

---

### 13. **Response Templates** (LOW IMPACT, EASY)

**Problem:** Repetitive structured responses

**Solution:** Use ultra-brief templates

**Templates:**
```markdown
# File created:
‚úÖ {filepath}

# File edited:
‚úÖ {filepath}:{lines} ‚Üí {change_summary}

# Test passed:
‚úÖ {test_name}

# Error found:
‚ùå {file}:{line} - {error}

# Status check:
üü¢ {service}: {status}
```

**Token Savings:** 10-20% on status updates

---

### 14. **Lazy Context Loading** (HIGH IMPACT)

**Problem:** Preloading unnecessary context

**Solution:** Load only when explicitly needed

**Implementation:**
```python
# BEFORE (Eager loading):
Session starts ‚Üí Load all:
- Project summary (500 tokens)
- All policies (1000 tokens)
- Recent history (800 tokens)
Total: 2300 tokens preloaded

# AFTER (Lazy loading):
Session starts ‚Üí Load minimal:
- Active task only (100 tokens)
- Load others on-demand
Total: 100 tokens initially (95% savings!)
```

**Token Savings:** 80-90% on session start

---

### 15. **File Type Optimization** (MEDIUM IMPACT)

**Problem:** Treating all files the same

**Solution:** Optimize per file type

**Strategies:**
```python
# JSON/YAML: Use jq/yq to extract specific keys
jq '.services.auth' config.json  # Not full file

# Logs: Use tail + grep, not full read
tail -100 app.log | grep ERROR  # Not all 10K lines

# Markdown: Read by section headers
grep -n "^##" README.md  # Get structure
Read specific section only

# Code: Use language-specific tools
- Java: jdtls for structure
- TS: typescript AST
- Python: ast module

# Binary/Media: Never read, just metadata
file image.png  # Type, size (NOT content)
```

**Token Savings:** 60-80% per file type

---

## üìà Expected Total Savings

**If all optimizations applied:**

| Optimization | Token Savings | Difficulty |
|-------------|---------------|------------|
| Smart Summarization | 70-80% | Medium |
| Tiered Caching | 30-40% | Easy |
| Diff-Based Editing | 90% | Easy |
| Smart Grep | 50-60% | Easy |
| Response Compression | 20-30% | Easy |
| AST Navigation | 80-95% | Hard |
| Session State Aggressive | 60-80% | Easy |
| Batch Operations | 40-50% | Medium |
| MCP Filtering | 70-80% | Medium |
| Conversation Pruning | 30-40% | Medium |
| Smart Tool Selection | 50-70% | Easy |
| Incremental Updates | 60-70% | Easy |
| Response Templates | 10-20% | Easy |
| Lazy Loading | 80-90% | Medium |
| File Type Optimization | 60-80% | Medium |

**Conservative Estimate (Easy + Medium only):**
**40-60% total token reduction across all operations** üéØ

**Aggressive Estimate (All optimizations):**
**70-85% total token reduction** üöÄ

---

## üõ†Ô∏è Implementation Priority

### Phase 1: Quick Wins (1-2 days)
1. ‚úÖ Response Compression (Easy, 20-30% savings)
2. ‚úÖ Diff-Based Editing (Easy, 90% savings)
3. ‚úÖ Smart Tool Selection (Easy, 50-70% savings)
4. ‚úÖ Response Templates (Easy, 10-20% savings)
5. ‚úÖ Smart Grep (Easy, 50-60% savings)

### Phase 2: Medium Effort (3-5 days)
6. ‚úÖ Tiered Caching (Easy-Medium, 30-40% savings)
7. ‚úÖ Session State Aggressive (Easy-Medium, 60-80% savings)
8. ‚úÖ Incremental Updates (Medium, 60-70% savings)
9. ‚úÖ File Type Optimization (Medium, 60-80% savings)
10. ‚úÖ Lazy Loading (Medium, 80-90% savings)

### Phase 3: Advanced (1-2 weeks)
11. ‚úÖ Smart Summarization (Medium-Hard, 70-80% savings)
12. ‚úÖ Batch Operations (Medium, 40-50% savings)
13. ‚úÖ MCP Filtering (Medium, 70-80% savings)
14. ‚úÖ Conversation Pruning (Medium, 30-40% savings)
15. ‚úÖ AST Navigation (Hard, 80-95% savings)

---

## üìä Monitoring Token Savings

**Create tracking system:**
```python
# Before each operation:
tokens_before = estimate_tokens()

# After operation:
tokens_after = estimate_tokens()

# Log savings:
savings = tokens_before - tokens_after
log(f"Saved {savings} tokens ({optimization_type})")
```

**Weekly report:**
```
Token Optimization Report - Week 7
====================================
Total Operations: 1,250
Total Tokens Saved: 487,000 (62% reduction)

Top Savers:
1. AST Navigation: 145K tokens (30%)
2. Session State: 98K tokens (20%)
3. Diff Editing: 87K tokens (18%)
4. Smart Grep: 72K tokens (15%)
5. Other: 85K tokens (17%)
```

---

## üéØ Recommended Actions

**Immediate (Today):**
1. Enable response compression mode
2. Implement diff-based edit confirmations
3. Add response templates
4. Enforce smart tool selection

**This Week:**
5. Implement tiered caching
6. Enable aggressive session state mode
7. Add file type optimizations

**This Month:**
8. Build AST navigation for Java/TypeScript
9. Implement smart summarization
10. Add MCP response filtering

---

**Version:** 1.0.0
**Last Updated:** 2026-02-10
**Impact:** 40-85% token reduction potential
