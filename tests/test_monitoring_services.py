#!/usr/bin/env python3
"""
Comprehensive Unit Tests for Monitoring Services

Tests all monitoring services including:
- MetricsCollector
- LogParser
- PolicyChecker
- SessionTracker
- MemorySystemMonitor
- PerformanceProfiler
- AutomationTracker
- SkillAgentTracker
- OptimizationTracker
"""

import unittest
import json
import tempfile
import os
from pathlib import Path
from datetime import datetime, timedelta
from unittest.mock import Mock, patch, MagicMock, mock_open
import sys

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))


class TestMetricsCollector(unittest.TestCase):
    """Test suite for MetricsCollector"""

    def setUp(self):
        """Set up test fixtures"""
        from services.monitoring.metrics_collector import MetricsCollector
        self.collector = MetricsCollector()

    def test_get_system_health_success(self):
        """Test successful system health retrieval"""
        # Mock memory_monitor: 10/10 daemons running = 100% health
        mock_daemons = [
            {'name': f'daemon-{i}', 'status': 'running', 'pid': 1000 + i, 'last_activity': None}
            for i in range(10)
        ]
        self.collector.memory_monitor.get_daemon_status = Mock(return_value=mock_daemons)

        health = self.collector.get_system_health()

        self.assertEqual(health['status'], 'healthy')
        self.assertEqual(health['health_score'], 100)
        self.assertEqual(health['running_daemons'], 10)

    def test_get_system_health_degraded(self):
        """Test degraded system health"""
        # Mock memory_monitor: 4/8 daemons running = 50% health (< 90 threshold)
        mock_daemons = []
        for i in range(8):
            status = 'running' if i < 4 else 'stopped'
            mock_daemons.append({
                'name': f'daemon-{i}',
                'status': status,
                'pid': 1000 + i if i < 4 else None,
                'last_activity': None
            })
        self.collector.memory_monitor.get_daemon_status = Mock(return_value=mock_daemons)

        health = self.collector.get_system_health()

        self.assertEqual(health['status'], 'degraded')
        self.assertLess(health['health_score'], 90)

    def test_get_system_health_failure(self):
        """Test system health on failure"""
        self.collector.memory_monitor.get_daemon_status = Mock(side_effect=Exception("Command failed"))

        health = self.collector.get_system_health()

        self.assertEqual(health['status'], 'unknown')
        self.assertEqual(health['health_score'], 0)

    @patch('subprocess.run')
    def test_get_daemon_status(self, mock_run):
        """Test daemon status retrieval"""
        mock_result = Mock()
        mock_result.returncode = 0
        mock_result.stdout = json.dumps({
            'daemons': {
                'context-daemon': {'is_running': True, 'pid': 1234},
                'session-daemon': {'is_running': False, 'pid': None}
            }
        })
        mock_run.return_value = mock_result

        daemons = self.collector.get_daemon_status()

        self.assertIsInstance(daemons, list)
        self.assertGreater(len(daemons), 0)


class TestLogParser(unittest.TestCase):
    """Test suite for LogParser - tests REAL LogParser class methods"""

    def setUp(self):
        """Set up test fixtures"""
        self.temp_dir = tempfile.mkdtemp()
        from services.monitoring.log_parser import LogParser
        self.parser = LogParser()
        # Override dirs to point at temp dir (isolate from real fs)
        self.parser.memory_dir = Path(self.temp_dir)
        self.parser.logs_dir = Path(self.temp_dir) / 'logs'
        self.parser.logs_dir.mkdir(parents=True, exist_ok=True)

    def tearDown(self):
        """Clean up"""
        import shutil
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)

    def test_get_available_logs_empty(self):
        """get_available_logs returns empty list when no log files"""
        logs = self.parser.get_available_logs()
        self.assertIsInstance(logs, list)
        self.assertEqual(len(logs), 0)

    def test_get_available_logs_with_files(self):
        """get_available_logs returns entries for each .log file"""
        (self.parser.logs_dir / 'policy-hits.log').write_text('line1\n', encoding='utf-8')
        (self.parser.logs_dir / 'daemon.log').write_text('line2\n', encoding='utf-8')

        logs = self.parser.get_available_logs()

        self.assertEqual(len(logs), 2)
        names = [l['name'] for l in logs]
        self.assertIn('policy-hits.log', names)
        for entry in logs:
            self.assertIn('name', entry)
            self.assertIn('size', entry)
            self.assertIn('modified', entry)

    def test_format_size_bytes(self):
        """_format_size correctly formats bytes"""
        result = self.parser._format_size(512)
        self.assertIn('B', result)

    def test_format_size_kilobytes(self):
        """_format_size correctly formats kilobytes"""
        result = self.parser._format_size(2048)
        self.assertIn('KB', result)

    def test_map_action_to_type_error(self):
        """_map_action_to_type returns error for ERROR keyword"""
        self.assertEqual(self.parser._map_action_to_type('ERROR occurred'), 'error')
        self.assertEqual(self.parser._map_action_to_type('FAILED'), 'error')

    def test_map_action_to_type_success(self):
        """_map_action_to_type returns success for OK keyword"""
        self.assertEqual(self.parser._map_action_to_type('COMPLETE'), 'success')
        self.assertEqual(self.parser._map_action_to_type('[OK]'), 'success')

    def test_map_action_to_type_info_default(self):
        """_map_action_to_type returns info for unknown actions"""
        self.assertEqual(self.parser._map_action_to_type('some action'), 'info')

    def test_get_recent_activity_no_log(self):
        """get_recent_activity returns empty list when no policy log"""
        activities = self.parser.get_recent_activity(limit=10)
        self.assertIsInstance(activities, list)
        self.assertEqual(len(activities), 0)

    def test_get_recent_activity_with_log(self):
        """get_recent_activity parses policy-hits.log entries"""
        log_content = '[2026-02-16 10:00:00] auto-fix-enforcer | SUCCESS | All checks passed\n'
        (self.parser.logs_dir / 'policy-hits.log').write_text(log_content, encoding='utf-8')

        activities = self.parser.get_recent_activity(limit=10)

        self.assertIsInstance(activities, list)
        self.assertGreaterEqual(len(activities), 1)

    def test_get_error_count_no_log(self):
        """get_error_count returns 0 when no log"""
        count = self.parser.get_error_count(hours=24)
        self.assertEqual(count, 0)


class TestPolicyChecker(unittest.TestCase):
    """Test suite for PolicyChecker - tests REAL PolicyChecker methods"""

    def setUp(self):
        """Set up test fixtures"""
        self.temp_dir = tempfile.mkdtemp()
        # PolicyChecker imports MemorySystemMonitor - patch it to avoid subprocess calls
        with patch('services.monitoring.policy_checker.MemorySystemMonitor'):
            from services.monitoring.policy_checker import PolicyChecker
            self.checker = PolicyChecker()
        self.checker.memory_dir = Path(self.temp_dir)

    def tearDown(self):
        """Clean up"""
        import shutil
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)

    def test_get_all_policies_returns_list(self):
        """get_all_policies returns a list"""
        policies = self.checker.get_all_policies()
        self.assertIsInstance(policies, list)

    def test_get_all_policies_has_required_fields(self):
        """Each policy entry has id, name, description, level"""
        policies = self.checker.get_all_policies()
        for policy in policies:
            self.assertIn('id', policy)
            self.assertIn('name', policy)
            self.assertIn('description', policy)
            self.assertIn('level', policy)

    def test_get_all_policies_contains_known_policies(self):
        """Known core policies appear in the list"""
        policies = self.checker.get_all_policies()
        ids = [p['id'] for p in policies]
        self.assertIn('auto-fix-enforcement', ids)
        self.assertIn('context-management', ids)

    def test_check_policy_status_returns_dict(self):
        """check_policy_status returns a dict with exists key"""
        status = self.checker.check_policy_status('auto-fix-enforcement')
        self.assertIsInstance(status, dict)
        self.assertIn('exists', status)


class TestSessionTracker(unittest.TestCase):
    """Test suite for SessionTracker - tests REAL SessionTracker methods"""

    def setUp(self):
        """Set up test fixtures"""
        self.temp_dir = tempfile.mkdtemp()
        from services.monitoring.session_tracker import SessionTracker
        self.tracker = SessionTracker()
        # Redirect to temp dir so tests don't touch real session files
        self.tracker.sessions_dir = Path(self.temp_dir) / 'sessions'
        self.tracker.sessions_dir.mkdir(parents=True, exist_ok=True)
        self.tracker.current_session_file = self.tracker.sessions_dir / 'current-session.json'
        self.tracker.sessions_history_file = self.tracker.sessions_dir / 'sessions-history.json'

    def tearDown(self):
        """Clean up"""
        import shutil
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)

    def test_get_current_session_creates_new_when_missing(self):
        """get_current_session creates a new session when no file exists"""
        session = self.tracker.get_current_session()
        self.assertIsInstance(session, dict)
        self.assertIn('session_id', session)
        self.assertIn('start_time', session)
        self.assertIn('status', session)

    def test_get_current_session_loads_existing(self):
        """get_current_session loads existing session file"""
        import json
        test_session = {
            'session_id': 'test-1234',
            'start_time': datetime.now().isoformat(),
            'status': 'active',
            'metrics': {}
        }
        with open(self.tracker.current_session_file, 'w') as f:
            json.dump(test_session, f)

        session = self.tracker.get_current_session()
        self.assertEqual(session['session_id'], 'test-1234')
        self.assertIn('duration_minutes', session)

    def test_get_sessions_history_empty(self):
        """get_sessions_history returns list when no history"""
        history = self.tracker.get_sessions_history()
        self.assertIsInstance(history, list)

    def test_update_session_metrics_returns_dict(self):
        """update_session_metrics returns a session dict"""
        session = self.tracker.update_session_metrics()
        self.assertIsInstance(session, dict)
        self.assertIn('session_id', session)


class TestMemorySystemMonitor(unittest.TestCase):
    """Test suite for MemorySystemMonitor - tests REAL MemorySystemMonitor methods"""

    def setUp(self):
        """Set up test fixtures"""
        self.temp_dir = tempfile.mkdtemp()
        from services.monitoring.memory_system_monitor import MemorySystemMonitor
        self.monitor = MemorySystemMonitor()
        # Redirect to temp dir
        self.monitor.memory_dir = Path(self.temp_dir)
        self.monitor.logs_dir = Path(self.temp_dir) / 'logs'
        self.monitor.sessions_dir = Path(self.temp_dir) / 'sessions'
        self.monitor.logs_dir.mkdir(parents=True, exist_ok=True)
        self.monitor.sessions_dir.mkdir(parents=True, exist_ok=True)

    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_get_daemon_status_returns_list(self):
        """get_daemon_status returns a list of daemon entries"""
        statuses = self.monitor.get_daemon_status()
        self.assertIsInstance(statuses, list)
        self.assertGreater(len(statuses), 0)

    def test_get_daemon_status_entries_have_required_fields(self):
        """Each daemon entry has name, status, pid, last_activity"""
        statuses = self.monitor.get_daemon_status()
        for entry in statuses:
            self.assertIn('name', entry)
            self.assertIn('status', entry)
            self.assertIn('pid', entry)

    def test_get_daemon_status_no_pid_files_gives_stopped(self):
        """When no PID files exist, all daemons are stopped"""
        statuses = self.monitor.get_daemon_status()
        for entry in statuses:
            self.assertIn(entry['status'], ['stopped', 'unknown', 'running'])

    def test_monitor_has_10_daemons(self):
        """Monitor tracks exactly 10 core daemons"""
        self.assertEqual(len(self.monitor.daemons), 10)

    def test_get_system_overview_returns_dict(self):
        """get_system_overview returns a dict with health info"""
        overview = self.monitor.get_system_overview()
        self.assertIsInstance(overview, dict)


class TestPerformanceProfiler(unittest.TestCase):
    """Test suite for PerformanceProfiler - tests REAL PerformanceProfiler"""

    def setUp(self):
        """Set up test fixtures with a real profiler using temp storage"""
        self.temp_dir = tempfile.mkdtemp()
        from services.monitoring.performance_profiler import PerformanceProfiler
        self.profiler = PerformanceProfiler(storage_dir=self.temp_dir)

    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_track_operation_does_not_raise(self):
        """track_operation runs without exception"""
        self.profiler.track_operation('Read', '/tmp/test.py', 150.0)
        self.assertTrue(True)

    def test_track_operation_adds_to_recent(self):
        """track_operation adds entry to recent_operations"""
        before = len(self.profiler.recent_operations)
        self.profiler.track_operation('Read', '/tmp/test.py', 100.0)
        self.assertEqual(len(self.profiler.recent_operations), before + 1)

    def test_slow_operation_added_to_slow_list(self):
        """Operations above SLOW_THRESHOLD appear in slow_operations"""
        self.profiler.track_operation('Read', '/tmp/big.py', 3000.0)
        self.assertGreater(len(self.profiler.slow_operations), 0)

    def test_fast_operation_not_in_slow_list(self):
        """Fast operations do not appear in slow_operations"""
        self.profiler.slow_operations.clear()
        self.profiler.track_operation('Read', '/tmp/small.py', 50.0)
        self.assertEqual(len(self.profiler.slow_operations), 0)

    def test_bottleneck_cache_updated(self):
        """Bottleneck cache is populated after tracking operations"""
        self.profiler.track_operation('Grep', 'pattern', 500.0)
        self.assertIn('Grep', self.profiler.bottleneck_cache)

    def test_track_multiple_operations(self):
        """Multiple operations tracked correctly"""
        self.profiler.track_operation('Read', '/a.py', 100.0)
        self.profiler.track_operation('Write', '/b.py', 200.0)
        self.profiler.track_operation('Grep', 'pattern', 300.0)
        self.assertEqual(len(self.profiler.recent_operations), 3)


class TestAutomationTracker(unittest.TestCase):
    """Test suite for AutomationTracker - tests REAL AutomationTracker methods"""

    def setUp(self):
        """Set up test fixtures"""
        self.temp_dir = tempfile.mkdtemp()
        from services.monitoring.automation_tracker import AutomationTracker
        self.tracker = AutomationTracker()
        # Redirect dirs to temp
        self.tracker.memory_dir = Path(self.temp_dir)
        self.tracker.logs_dir = Path(self.temp_dir) / 'logs'
        self.tracker.sessions_dir = Path(self.temp_dir) / 'sessions'
        self.tracker.logs_dir.mkdir(parents=True, exist_ok=True)
        self.tracker.sessions_dir.mkdir(parents=True, exist_ok=True)

    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_get_session_start_recommendations_no_file(self):
        """get_session_start_recommendations returns unavailable when no file"""
        result = self.tracker.get_session_start_recommendations()
        self.assertIsInstance(result, dict)
        self.assertIn('available', result)
        self.assertFalse(result['available'])

    def test_get_session_start_recommendations_with_file(self):
        """get_session_start_recommendations loads file when it exists"""
        import json
        check_file = self.tracker.memory_dir / '.last-automation-check.json'
        check_file.write_text(json.dumps({
            'model': 'HAIKU',
            'skills': ['docker'],
            'context_status': 'GREEN',
            'context_percentage': 45
        }), encoding='utf-8')

        result = self.tracker.get_session_start_recommendations()
        self.assertTrue(result['available'])
        self.assertEqual(result['model_recommendation'], 'HAIKU')

    def test_get_task_breakdown_stats_returns_dict(self):
        """get_task_breakdown_stats returns a dict"""
        stats = self.tracker.get_task_breakdown_stats()
        self.assertIsInstance(stats, dict)

    def test_get_auto_commit_stats_returns_dict(self):
        """get_auto_commit_stats returns a dict"""
        stats = self.tracker.get_auto_commit_stats()
        self.assertIsInstance(stats, dict)


class TestSkillAgentTracker(unittest.TestCase):
    """Test suite for SkillAgentTracker - tests REAL SkillAgentTracker methods"""

    def setUp(self):
        """Set up test fixtures"""
        self.temp_dir = tempfile.mkdtemp()
        from services.monitoring.skill_agent_tracker import SkillAgentTracker
        self.tracker = SkillAgentTracker()
        # Redirect dirs to temp
        self.tracker.memory_dir = Path(self.temp_dir)
        self.tracker.logs_dir = Path(self.temp_dir) / 'logs'
        self.tracker.skills_dir = Path(self.temp_dir) / 'skills'
        self.tracker.logs_dir.mkdir(parents=True, exist_ok=True)
        self.tracker.skills_dir.mkdir(parents=True, exist_ok=True)

    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_get_skill_selection_stats_no_log(self):
        """get_skill_selection_stats returns dict when no log file"""
        stats = self.tracker.get_skill_selection_stats()
        self.assertIsInstance(stats, dict)
        self.assertIn('total_skill_invocations', stats)

    def test_get_skill_selection_stats_with_log(self):
        """get_skill_selection_stats parses log file entries"""
        log_content = '[2026-02-18 10:00:00] skill-selector | SELECTED | java-spring-boot-microservices\n'
        (self.tracker.logs_dir / 'policy-hits.log').write_text(log_content, encoding='utf-8')
        stats = self.tracker.get_skill_selection_stats()
        self.assertIsInstance(stats, dict)
        self.assertIn('total_skill_invocations', stats)

    def test_get_plan_mode_stats_returns_dict(self):
        """get_plan_mode_stats returns a dict"""
        stats = self.tracker.get_plan_mode_stats()
        self.assertIsInstance(stats, dict)

    def test_get_agent_invocation_stats_returns_dict(self):
        """get_agent_invocation_stats returns a dict"""
        stats = self.tracker.get_agent_invocation_stats()
        self.assertIsInstance(stats, dict)


class TestOptimizationTracker(unittest.TestCase):
    """Test suite for OptimizationTracker - tests REAL OptimizationTracker methods"""

    def setUp(self):
        """Set up test fixtures"""
        self.temp_dir = tempfile.mkdtemp()
        from services.monitoring.optimization_tracker import OptimizationTracker
        self.tracker = OptimizationTracker()
        # Redirect dirs to temp
        self.tracker.memory_dir = Path(self.temp_dir)
        self.tracker.logs_dir = Path(self.temp_dir) / 'logs'
        self.tracker.docs_dir = Path(self.temp_dir) / 'docs'
        self.tracker.logs_dir.mkdir(parents=True, exist_ok=True)
        self.tracker.docs_dir.mkdir(parents=True, exist_ok=True)

    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_get_tool_optimization_metrics_returns_dict(self):
        """get_tool_optimization_metrics returns dict with strategy entries"""
        metrics = self.tracker.get_tool_optimization_metrics()
        self.assertIsInstance(metrics, dict)

    def test_get_tool_optimization_metrics_has_15_strategies(self):
        """get_tool_optimization_metrics contains all 15 strategies"""
        metrics = self.tracker.get_tool_optimization_metrics()
        # May return 'strategies' key or flat dict - handle both
        if 'strategies' in metrics:
            strategies = metrics['strategies']
        else:
            strategies = metrics
        self.assertGreaterEqual(len(strategies), 10)

    def test_get_context_savings_returns_dict(self):
        """get_context_savings returns a dict"""
        savings = self.tracker.get_context_savings()
        self.assertIsInstance(savings, dict)

    def test_get_optimization_summary_returns_dict(self):
        """get_optimization_summary returns a dict"""
        summary = self.tracker.get_optimization_summary()
        self.assertIsInstance(summary, dict)


if __name__ == '__main__':
    unittest.main()
